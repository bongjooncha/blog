{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>BGD(Batch Gradient Descent)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "식은 y = 3x + 4 에서 약간의 노이즈를 추가\n",
    "\n",
    "random.rand(100,1): 0이상 1이하의 숫로 이루어진 100 x 1 배열 생성\n",
    "\n",
    "random.randn(100,1): 표준 정규분포에서 무작위로 선택된 100 x 1 배열 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가상의 데이터 생성\n",
    "np.random.seed(42)    \n",
    "\n",
    "X = 2 * np.random.rand(100, 1) \n",
    "y = 4 + 3 * X + np.random.randn(100, 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ones(100,1): 1로 채워진 100 x 1 배열 생성, c_[ ]는 c_배열 안의 두 배열을 더함. (100 x 2) 배열이 됨\n",
    "\n",
    "여기서 앞을 1로 체운 이유는 상수는 X와 같이 따로 대입해야 할 값이 없기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = np.c_[np.ones((100, 1)), X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| lr | n_iterations | m |\n",
    "|-----|--------------|---|\n",
    "|학습률| 반복횟수(몇 번의 epoch이 진행될 것인지 의미) | 학습에 사용된 샘플 수|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기값 설정\n",
    "lr = 0.1                  \n",
    "n_iterations = 1000        \n",
    "m = 100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "theta_bgd는 bgd가 찾고자하는 변수이다. 현재 2개의 변수를 찾아야 하기에 랜덤한 숫자로 만들어지 2 x 1 배열을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Gradient Descent (BGD) 구현\n",
    "theta_bgd = np.random.randn(2, 1)  \n",
    "theta_bgd_path = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mse 함수](./img/mse_function.png)\n",
    "\n",
    " 이 코드에서 사용한 손실함수(loss funciton)은 MSE이다. MSE는 실제값과 예측치 theta를 넣고 계산한 값의 차를 제곱한 후 평균을 내는 손실함수이다.\n",
    "\n",
    "\n",
    "![편미분한 mse 함수](./img/mse_func_diff.png)\n",
    "\n",
    "MSE를 편미분하면 위와 같다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_b.dot(theta_bgd)은 X_b와 theta_bgd를 행렬 곱한다. theta_bgd는 y = 3x + 4에서 3과 4의 추정치를 의미하고, X_b는 x와 상수 4에 곱할 1을 의미한다. 따라서 X_b.dot(theta_bgd)는 예측한 θ값 에서의 y 값을 의미한다.\n",
    "\n",
    "<strong>gradients = 2/m * X_b.T.dot(X_b.dot(theta_bgd) - y)</strong>에서 (X_b.dot(theta_bgd) - y)는 실제값과 예측치의 차이 값,<br/><br/>\n",
    "X_b.T.dot(X_b.dot(theta_bgd) - y)는 위에서 구한 차이 값에 편미분으로 인해 남겨진 θ값, X_b를 통해 X_b.T를 통해 전치 시킨 이후 곱한다. 각 θ에 대한 기울기 값을 구할수 있다.\n",
    "\n",
    "\n",
    "<br/><br/><br/><br/>\n",
    "gradient는 편미분 한 MSE의 값을 의미한다.\n",
    "\n",
    "<strong>theta_bgd = theta_bgd - eta * gradients</strong>는 이전에 예측한 θ값에서 위에서 구한 gradient(기울기)*eta(학습률)을 빼 오차율이 적은 θ값을 구한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.10103284]\n",
      "  [2.5689581 ]]\n",
      "\n",
      " [[1.76167724]\n",
      "  [3.20430202]]\n",
      "\n",
      " [[2.17070217]\n",
      "  [3.55850018]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[4.21509616]\n",
      "  [2.77011339]]\n",
      "\n",
      " [[4.21509616]\n",
      "  [2.77011339]]\n",
      "\n",
      " [[4.21509616]\n",
      "  [2.77011339]]]\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(n_iterations):  # 1회 반복 당 시행되는 과정\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta_bgd) - y)\n",
    "    theta_bgd = theta_bgd - lr * gradients\n",
    "    theta_bgd_path.append(theta_bgd)\n",
    "    \n",
    "theta_bgd_path = np.array(theta_bgd_path)\n",
    "print(theta_bgd_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
